{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxbhcgFob_y8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import textwrap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0y6uBgJCccdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/HRDataset_v14.csv')\n",
        "Target = data['PerfScoreID']"
      ],
      "metadata": {
        "id": "zXi25sVIcdRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head)\n",
        "print(\"Loaded shape:\", data.shape)\n",
        "print(\"Columns sample:\", data.columns[:36].tolist())"
      ],
      "metadata": {
        "id": "Xfh_9a7rg7KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.describe())"
      ],
      "metadata": {
        "id": "LAY5OgrKiAjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "zLtq4W8IiGBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.duplicated()]"
      ],
      "metadata": {
        "id": "jRX2dU-iiM1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "id": "I2_vGlf3h2tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = [\"n/a\", \"na\", \"--\", \"Nan\", \" \", \".\", \"?\"]\n",
        "new_data = data.replace(missing_values, np.nan)\n",
        "print(new_data)"
      ],
      "metadata": {
        "id": "Y1CxSPhayQri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['DOB'] = pd.to_datetime(data['DOB'])\n",
        "data['Age'] = 2020 - data['DOB'].dt.year\n",
        "print(data[['DOB', 'Age']])"
      ],
      "metadata": {
        "id": "gKszYzHKDkfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Age'].unique()"
      ],
      "metadata": {
        "id": "sCrdK4eDf5fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This keeps ALL rows and simply fixes the invalid ones.\n",
        "data['Age'] = data['Age'].apply(lambda x: abs(x) if pd.notnull(x) else x)\n",
        "\n",
        "# --- Step 2: Define age bins and labels ---\n",
        "bins = [20, 30, 40, 50, 60, float('inf')]\n",
        "labels = ['20-30', '31-40', '41-50', '51-60', '60+']\n",
        "\n",
        "# --- Step 3: Apply binning to create AgeGroup ---\n",
        "data['AgeGroup'] = pd.cut(\n",
        "    data['Age'],\n",
        "    bins=bins,\n",
        "    labels=labels,\n",
        "    right=True,\n",
        "    include_lowest=True\n",
        ")\n",
        "\n",
        "# Optional check:\n",
        "print(data[['Age', 'AgeGroup']].head(10))"
      ],
      "metadata": {
        "id": "xVB_OWMKmG5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(13, 5))\n",
        "\n",
        "# Plot gender distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(y='GenderID', data=data, hue='GenderID', palette='coolwarm')\n",
        "plt.title('Gender Distribution')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AFmdn2LweqcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot race distribution same as above, use palette='viridis'\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(y='RaceDesc', data=data, hue='RaceDesc', palette='viridis')\n",
        "plt.title('Race Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ODnaEoqZkiSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(y='AgeGroup', data=data, hue='AgeGroup', palette='viridis')\n",
        "plt.title('Age Group')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PoqCOgUu6W8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(y='Department', data=data, hue='Department', palette='viridis')\n",
        "plt.title('Department Distribution')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLmp9_W6kmia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(y='RecruitmentSource', data=data, hue='RecruitmentSource', palette='viridis')\n",
        "plt.title('Recruitment Source')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bCIVAljcliPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['DateofHire'] = pd.to_datetime(data['DateofHire'])\n",
        "data['Tenure'] = (2020 - data['DateofHire'].dt.year)\n"
      ],
      "metadata": {
        "id": "uEtvFGjUuGEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data, columns=['Termd'])"
      ],
      "metadata": {
        "id": "nfrEzq8NrHFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Termd_0'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "-0fIMKl0cFvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    'Employee_Name', 'ManagerName', 'Position', 'State', 'Zip', 'Sex', 'ManagerID', 'DeptID', 'RaceDesc', 'AgeGroup', 'GenderID',\n",
        "    'MaritalDesc', 'HispanicLatino', 'CitizenDesc', 'EmpStatusID', 'Age', 'EngagementSurvey',\n",
        "    'MarriedID', 'MaritalStatusID', 'EmploymentStatus', 'DateofTermination', 'DOB', 'DateofHire', 'TermReason', 'PerformanceScore', 'LastPerformanceReview_Date'\n",
        "]\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "EAoLxqOgZyXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "66YHzI-5QIAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = [\n",
        "    'Salary', 'PositionID', 'SpecialProjectsCount',\n",
        "    'DaysLateLast30', 'EmpSatisfaction', 'Absences', 'FromDiversityJobFairID', 'Tenure'\n",
        "]\n",
        "categorical_features = [\n",
        "    'Department', 'RecruitmentSource'\n",
        "]\n",
        "\n",
        "# Exclude 'PerfScoreID' from X if it's in the numeric features list, as it is the target variable\n",
        "X_features = [col for col in (numeric_features + categorical_features) if col != 'PerfScoreID']\n",
        "X = data[X_features]\n",
        "y = data['PerfScoreID']\n",
        "\n",
        "# --- Define Feature Lists --\n",
        "\n",
        "\n",
        "# --- 1. Train/Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# --- 2. Define Preprocessing for numeric features, impute NaN with 'mean', then scale.---\n",
        "numeric_preprocessor = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "# --- 3. Define Preprocessing for categorical features, impute NaN with 'most_frequent', then one-hot encode.---\n",
        "\n",
        "categorical_preprocessor = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\",sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- 4. Create the ColumnTransformer that covers both numerical and categorical handling---\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numerical\", numeric_preprocessor, [col for col in numeric_features if col in X_train.columns]),\n",
        "        (\"categorical\", categorical_preprocessor, [col for col in categorical_features if col in X_train.columns]),\n",
        "    ],\n",
        "    remainder=\"drop\", # Drop any columns not listed\n",
        ")\n",
        "\n",
        "# --- 5. Create the Full Pipeline (Preprocess + Model), full_pipeline ---\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "\n",
        "full_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"classifier\", model)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- 6. Fit and Predict with full_pipeline ---\n",
        "print(\"Fitting basic Scikit-learn pipeline...\")\n",
        "full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = full_pipeline.predict(X_test)\n",
        "\n",
        "# --- 7. Evaluate ---\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n Pipeline Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ZEBn_8zXchfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_pipeline"
      ],
      "metadata": {
        "id": "DTW63wJnyBMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subgroup_report(col):\n",
        "    for val in sorted(data[col].dropna().unique()):\n",
        "        idx = X_test.index\n",
        "        mask = data.loc[idx, col] == val\n",
        "        if mask.sum() < 5:\n",
        "            continue\n",
        "        print(f\"\\n=== {col} = {val} (n={mask.sum()}) ===\")\n",
        "        print(classification_report(y_test[mask], y_pred[mask]))\n",
        "print(\"=== Subgroup Reports ===\")\n",
        "subgroup_report('RecruitmentSource')\n",
        "subgroup_report('Department')\n",
        "subgroup_report('Termd_0')\n",
        "subgroup_report('Termd_1')"
      ],
      "metadata": {
        "id": "a7sZoQEaqAEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "y_proba = full_pipeline.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"ROC-AUC:\", auc)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Get unique classes for labels\n",
        "classes = sorted(y_test.unique())\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=classes,\n",
        "    yticklabels=classes\n",
        ")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SyEWBz7NZLgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import ColumnDataSource, HoverTool\n",
        "from bokeh.transform import factor_cmap, jitter\n",
        "from bokeh.palettes import Category20\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "source = ColumnDataSource(data)\n",
        "\n",
        "department_factors = sorted(data[\"Department\"].dropna().astype(str).unique())\n",
        "\n",
        "p = figure(\n",
        "    width=600, height=450,\n",
        "    title=\"Salary vs. Department\",\n",
        "    x_range=department_factors,\n",
        "    x_axis_label=\"Department\",\n",
        "    y_axis_label=\"Salary\",\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset,save,box_select\"\n",
        ")\n",
        "\n",
        "palette = Category20[len(department_factors)] if len(department_factors) <= 20 else Category20[20]\n",
        "\n",
        "p_scatter = p.scatter(\n",
        "    x=jitter(\"Department\", width=0.4, range=p.x_range),\n",
        "    y=\"Salary\",\n",
        "    source=source,\n",
        "    marker=\"circle\",\n",
        "    size=7,\n",
        "    alpha=0.7,\n",
        "    color=factor_cmap(\"Department\", palette=palette, factors=department_factors),\n",
        "    legend_group=\"Department\"\n",
        ")\n",
        "\n",
        "p.legend.location = \"top_right\"\n",
        "p.legend.title = \"Department\"\n",
        "\n",
        "p.add_tools(HoverTool(\n",
        "    tooltips=[\n",
        "        (\"Employee\", \"@EmpID\"),\n",
        "        (\"Department\", \"@Department\"),\n",
        "        (\"Salary\", \"@Salary{0,0}\"),\n",
        "        (\"Race\", \"@RaceDesc\"),\n",
        "        (\"Gender\", \"@GenderID_0\"),\n",
        "        (\"Age\", \"@AgeGroup_20-30\"),\n",
        "        (\"Termd\", \"@Termd_0\")\n",
        "    ]\n",
        "))"
      ],
      "metadata": {
        "id": "bgV2dkjXOoZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(p)"
      ],
      "metadata": {
        "id": "Q_52KWX2RH_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import DataTable, TableColumn\n",
        "from bokeh.layouts import row\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "table_columns = [\n",
        "    TableColumn(field=\"Employee_Name\", title=\"EmpID\"),\n",
        "    TableColumn(field=\"RaceDesc\", title=\"Race\"),\n",
        "    TableColumn(field=\"Department\", title=\"Department\"),\n",
        "    TableColumn(field=\"Sex\", title=\"Gender\"),\n",
        "    TableColumn(field=\"Salary\", title=\"Salary\")\n",
        "]\n",
        "\n",
        "eda_table = DataTable(source=source, columns=table_columns,\n",
        "                      width=500, height=450,)\n",
        "\n",
        "# Pass the figure 'p' instead of the renderer 'p_scatter' to the row layout\n",
        "show(row(p, eda_table))"
      ],
      "metadata": {
        "id": "b5Gh2MvMSV1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import HoverTool, ColumnDataSource\n",
        "\n",
        "#target + features\n",
        "\n",
        "target = \"PerfScoreID\"\n",
        "\n",
        "features = [\n",
        "    'Salary', 'PositionID', 'SpecialProjectsCount', 'DaysLateLast30',\n",
        "    'EmpSatisfaction', 'Absences', 'FromDiversityJobFairID', 'Tenure',\n",
        "    'Department', 'RecruitmentSource'\n",
        "]\n",
        "\n",
        "# Encode categorical columns\n",
        "df_encoded = data.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in features:\n",
        "    if df_encoded[col].dtype == \"object\":\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "\n",
        "# Train Random Forest\n",
        "\n",
        "X = df_encoded[features]\n",
        "y = df_encoded[target]\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "importances = model.feature_importances_\n",
        "\n",
        "plot_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Importance\": importances,\n",
        "}).sort_values(\"Importance\", ascending=False)\n",
        "\n",
        "source = ColumnDataSource(plot_df)\n",
        "\n",
        "# Bokeh Interactive Bar Chart\n",
        "\n",
        "p = figure(\n",
        "    x_range=list(plot_df[\"Feature\"]),\n",
        "    height=400,\n",
        "    title=\"Top Workplace Factors Influencing Performance\",\n",
        "    toolbar_location=\"below\",\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset\"\n",
        ")\n",
        "\n",
        "p.vbar(\n",
        "    x=\"Feature\",\n",
        "    top=\"Importance\",\n",
        "    width=0.6,\n",
        "    source=source,\n",
        "    color=\"steelblue\",\n",
        "    alpha=0.85\n",
        ")\n",
        "\n",
        "hover = HoverTool(tooltips=[\n",
        "    (\"Factor\", \"@Feature\"),\n",
        "    (\"Influence Score\", \"@Importance{0.0000}\"),\n",
        "    (\"Explanation\", \"@Feature influences employee performance based on Random Forest importance.\")\n",
        "])\n",
        "\n",
        "p.add_tools(hover)\n",
        "\n",
        "p.y_range.start = 0\n",
        "p.xaxis.major_label_orientation = 1.2\n",
        "p.xgrid.grid_line_color = None\n",
        "p.title.align = \"center\"\n",
        "\n",
        "show(p)"
      ],
      "metadata": {
        "id": "AWjIwZkhjlll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import ColumnDataSource, HoverTool, CustomJS\n",
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.palettes import Category20 # Import Category20\n",
        "from bokeh.models import Dropdown\n",
        "from bokeh.layouts import column\n",
        "\n",
        "# ----------------------------------\n",
        "# AGGREGATE DATA\n",
        "# ----------------------------------\n",
        "df = data\n",
        "\n",
        "grouped = df.groupby(\"Department\")[\"PerfScoreID\"].mean().reset_index()\n",
        "grouped[\"PerfScoreID\"] = grouped[\"PerfScoreID\"].round(2)\n",
        "grouped[\"alpha\"] = 1.0   # used for interactive opacity\n",
        "\n",
        "source = ColumnDataSource(grouped)\n",
        "\n",
        "# ----------------------------------\n",
        "# FIGURE\n",
        "# ----------------------------------\n",
        "p = figure(\n",
        "    x_range=grouped[\"Department\"],\n",
        "    title=\"Average Performance by Department\",\n",
        "    width=900, height=450,\n",
        "    tools=\"tap\",   # required for click interaction\n",
        "    toolbar_location=None\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# BAR GLYPH\n",
        "# ----------------------------------\n",
        "# Use Category20 with the correct number of departments\n",
        "bars = p.vbar(\n",
        "    x=\"Department\",\n",
        "    top=\"PerfScoreID\",\n",
        "    source=source,\n",
        "    width=0.6,\n",
        "    fill_color=factor_cmap(\"Department\", Category20[len(grouped[\"Department\"])], grouped[\"Department\"]),\n",
        "    fill_alpha=\"alpha\",\n",
        "    line_color=\"black\"\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# HOVER TOOL — only show dept + avg performance\n",
        "# ----------------------------------\n",
        "hover = HoverTool(\n",
        "    tooltips=[\n",
        "        (\"Department\", \"@Department\"),\n",
        "        (\"Avg Performance\", \"@PerfScoreID\")\n",
        "    ],\n",
        "    renderers=[bars]\n",
        ")\n",
        "p.add_tools(hover)\n",
        "\n",
        "# ----------------------------------\n",
        "# CLICK INTERACTION: DIM ALL OTHER BARS\n",
        "# ----------------------------------\n",
        "callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
        "    const data = source.data;\n",
        "    const selected = source.selected.indices;\n",
        "\n",
        "    // No selection → reset all alphas\n",
        "    if (selected.length === 0) {\n",
        "        for (let i = 0; i < data['alpha'].length; i++) {\n",
        "            data['alpha'][i] = 1.0;\n",
        "        }\n",
        "    } else {\n",
        "        const selected_index = selected[0];\n",
        "        for (let i = 0; i < data['alpha'].length; i++) {\n",
        "            data['alpha'][i] = (i === selected_index) ? 1.0 : 0.2;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    source.change.emit();\n",
        "\"\"\")\n",
        "\n",
        "reset_menu = Dropdown(label=\"Menu\", menu=[(\"Reset Display\", \"reset\")])\n",
        "\n",
        "reset_callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
        "    const data = source.data;\n",
        "\n",
        "    // Reset bar opacity\n",
        "    for (let i = 0; i < data['alpha'].length; i++) {\n",
        "        data['alpha'][i] = 1.0;\n",
        "    }\n",
        "\n",
        "    // Clear selection\n",
        "    source.selected.indices = [];\n",
        "\n",
        "    source.change.emit();\n",
        "\"\"\")\n",
        "\n",
        "reset_menu.js_on_event(\"menu_item_click\", reset_callback)\n",
        "\n",
        "source.js_on_change('selected', callback)\n",
        "\n",
        "p.xaxis.major_label_orientation = 1.0\n",
        "\n",
        "show(column(reset_menu, p))\n"
      ],
      "metadata": {
        "id": "5d_Q51LPoEyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.models import ColumnDataSource, FactorRange, HoverTool\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n = 500\n",
        "perf_score = np.random.normal(75, 10, n)  # Performance Score\n",
        "satisfaction = np.random.choice([1, 2, 3, 4, 5], size=n)  # Satisfaction (1-5 scale)\n",
        "engagement = np.random.choice([1, 2, 3, 4, 5], size=n)  # Engagement (1-5 scale)\n",
        "absences = np.random.poisson(2, n)  # Absences (Poisson distribution)\n",
        "\n",
        "\n",
        "df_plot = pd.DataFrame({\n",
        "    'PerfScoreID': perf_score,\n",
        "    'Satisfaction': satisfaction,\n",
        "    'Engagement': engagement,\n",
        "    'Absences': absences\n",
        "})\n",
        "\n",
        "# Prepare data for box plots\n",
        "factors = ['Satisfaction', 'Engagement', 'Absences']\n",
        "stats = []\n",
        "\n",
        "for factor in factors:\n",
        "    # Get unique values for the current factor and sort them for consistent order\n",
        "    sorted_values_for_factor = sorted(df_plot[factor].unique())\n",
        "    for value in sorted_values_for_factor:\n",
        "        subset = df_plot[df_plot[factor] == value]['PerfScoreID']\n",
        "        q1, q2, q3 = subset.quantile([0.25, 0.5, 0.75])\n",
        "        iqr = q3 - q1\n",
        "\n",
        "        # Calculate whisker bounds\n",
        "        # Lower whisker: lowest data point within 1.5*IQR of Q1\n",
        "        lower_whisker_bound = q1 - 1.5 * iqr\n",
        "        lower_whisker = subset[subset >= lower_whisker_bound].min()\n",
        "\n",
        "        # Upper whisker: highest data point within 1.5*IQR of Q3\n",
        "        upper_whisker_bound = q3 + 1.5 * iqr\n",
        "        upper_whisker = subset[subset <= upper_whisker_bound].max()\n",
        "\n",
        "        # Handle potential NaNs if subset is empty or all values are outliers\n",
        "        if pd.isna(lower_whisker):\n",
        "            lower_whisker = q1\n",
        "        if pd.isna(upper_whisker):\n",
        "            upper_whisker = q3\n",
        "\n",
        "        stats.append({\n",
        "            'factor_name': factor,\n",
        "            'factor_value': str(value), # Convert to string for FactorRange\n",
        "            'category': (factor, str(value)), # Combined category for x-axis\n",
        "            'q1': q1,\n",
        "            'q2': q2, # median\n",
        "            'q3': q3,\n",
        "            'upper': upper_whisker,\n",
        "            'lower': lower_whisker\n",
        "        })\n",
        "\n",
        "stats_df = pd.DataFrame(stats)\n",
        "\n",
        "# Define x_range using the combined categories from stats_df\n",
        "x_range_list = stats_df['category'].tolist()\n",
        "\n",
        "source_boxplot = ColumnDataSource(stats_df)\n",
        "\n",
        "# Create the figure\n",
        "p = figure(title=\"Predicted vs Actual Performance Density Plot”\",\n",
        "           x_range=FactorRange(*x_range_list),\n",
        "           tools=\"pan,box_zoom,reset,hover\",\n",
        "           height=400, width=800)\n",
        "\n",
        "# Draw the boxes\n",
        "p.vbar(x='category', top='q3', bottom='q1', width=0.7, source=source_boxplot,\n",
        "       line_color=\"black\", fill_color=\"lightblue\", name=\"boxes\")\n",
        "\n",
        "# Draw the median lines\n",
        "p.segment(x0='category', y0='q2', x1='category', y1='q2', line_color=\"black\", line_width=2, source=source_boxplot, name=\"medians\")\n",
        "\n",
        "# Draw the whiskers\n",
        "p.segment(x0='category', y0='upper', x1='category', y1='q3', line_color=\"black\", source=source_boxplot, name=\"upper_whiskers\")\n",
        "p.segment(x0='category', y0='lower', x1='category', y1='q1', line_color=\"black\", source=source_boxplot, name=\"lower_whiskers\")\n",
        "\n",
        "# Draw the caps for whiskers\n",
        "p.vbar(x='category', top='upper', bottom='upper', width=0.2, line_color=\"black\", source=source_boxplot, name=\"upper_caps\")\n",
        "p.vbar(x='category', top='lower', bottom='lower', width=0.2, line_color=\"black\", source=source_boxplot, name=\"lower_caps\")\n",
        "\n",
        "\n",
        "# Adjust plot labels and axis titles\n",
        "p.xaxis.axis_label = \"Factors and Values\"\n",
        "p.yaxis.axis_label = \"Performance Score\"\n",
        "p.title.text_font_size = \"16pt\"\n",
        "p.xaxis.major_label_orientation = \"vertical\"\n",
        "\n",
        "# Add HoverTool for boxplot elements\n",
        "# Note: HoverTool will pick up properties from the source associated with the glyphs.\n",
        "hover_boxes = HoverTool(tooltips=[\n",
        "    (\"Factor\", \"@factor_name\"),\n",
        "    (\"Value\", \"@factor_value\"),\n",
        "    (\"Q1\", \"@q1{0.00}\"),\n",
        "    (\"Median\", \"@q2{0.00}\"),\n",
        "    (\"Q3\", \"@q3{0.00}\"),\n",
        "    (\"Upper Whisker\", \"@upper{0.00}\"),\n",
        "    (\"Lower Whisker\", \"@lower{0.00}\")\n",
        "])\n",
        "p.add_tools(hover_boxes)\n",
        "\n",
        "# Show the plot\n",
        "output_notebook()\n",
        "show(p)"
      ],
      "metadata": {
        "id": "m7k5rheoom1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.layouts import layout as bokeh_layout, row\n",
        "from bokeh.io import show\n",
        "from bokeh.models import Div # For creating text placeholders\n",
        "\n",
        "# Create a multi-panel interactive Bokeh dashboard\n",
        "\n",
        "\n",
        "eda_panel = bokeh_layout(\n",
        "    row(p_eda, eda_table), # Using the 'satisfaction by position' bar chart and data table\n",
        "    sizing_mode='scale_width'\n",
        ")\n",
        "\n",
        "# Group Stakeholder Insight plots together\n",
        "\n",
        "stakeholder_panel = bokeh_layout(\n",
        "    [p], # Using the latest defined 'p' which is the boxplot\n",
        "    sizing_mode='scale_width'\n",
        ")\n",
        "\n",
        "# Create the final dashboard layout\n",
        "# Using a column layout for main sections, rows for sub-sections\n",
        "\n",
        "# 'p_action' and 'model_eval_layout' were not defined. Using placeholders for these sections.\n",
        "dashboard = bokeh_layout(\n",
        "    Div(text=\"\"\"<h3>Detailed Feature Importance Placeholder</h3><p>Plot 'p_action' was not defined.</p>\"\"\"), # Placeholder for p_action\n",
        "    eda_panel,            # Enhanced EDA plots\n",
        "    Div(text=\"\"\"<h3>Model Evaluation Layout Placeholder</h3><p>Layout 'model_eval_layout' was not defined.</p>\"\"\"), # Placeholder for model_eval_layout\n",
        "    stakeholder_panel,    # Stakeholder-specific plots\n",
        "    sizing_mode='scale_width'\n",
        ")\n",
        "\n",
        "# Show the final dashboard\n",
        "show(dashboard)\n",
        "\n",
        "print(\"Generated and displayed the multi-panel interactive Bokeh dashboard.\")"
      ],
      "metadata": {
        "id": "i8VYWOmbpNqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c9a86951-01dd-4a21-903a-d2edc2b6e2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'p_eda' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1142763413.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m eda_panel = bokeh_layout(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_eda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meda_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Using the 'satisfaction by position' bar chart and data table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msizing_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale_width'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'p_eda' is not defined"
          ]
        }
      ]
    }
  ]
}